{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205b0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"i love nlp\", \"i teach gen ai\", \"i am working with iub\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'love',\n",
       " 'nlp',\n",
       " 'i',\n",
       " 'teach',\n",
       " 'gen',\n",
       " 'ai',\n",
       " 'i',\n",
       " 'am',\n",
       " 'working',\n",
       " 'with',\n",
       " 'iub']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(corpus).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a359a11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ai', 'am', 'gen', 'i', 'iub', 'love', 'nlp', 'teach', 'with', 'working'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(\" \".join(corpus).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set(\" \".join(corpus).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d655d09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['working', 'i', 'am', 'nlp', 'gen', 'with', 'love', 'ai', 'iub', 'teach']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'working')\n",
      "(1, 'i')\n",
      "(2, 'am')\n",
      "(3, 'nlp')\n",
      "(4, 'gen')\n",
      "(5, 'with')\n",
      "(6, 'love')\n",
      "(7, 'ai')\n",
      "(8, 'iub')\n",
      "(9, 'teach')\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(unique_words):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it to a dictionary with indexes\n",
    "word_to_index = {word: i for i, word in enumerate(unique_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'working': 0,\n",
       " 'i': 1,\n",
       " 'am': 2,\n",
       " 'nlp': 3,\n",
       " 'gen': 4,\n",
       " 'with': 5,\n",
       " 'love': 6,\n",
       " 'ai': 7,\n",
       " 'iub': 8,\n",
       " 'teach': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80235",
   "metadata": {},
   "source": [
    "## One hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73974e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love nlp\n",
      "[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]]\n",
      "i teach gen ai\n",
      "[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]\n",
      "i am working with iub\n",
      "[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_vector = []\n",
    "for sentence in corpus:\n",
    "    print(sentence)\n",
    "    sentence_vector = []\n",
    "    for word in sentence.split():\n",
    "        vector = [0] * len(unique_words)\n",
    "        vector[word_to_index[word]] = 1\n",
    "        sentence_vector.append(vector)\n",
    "    print(sentence_vector)\n",
    "    one_hot_vector.append(sentence_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d58954c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9c2470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273b85d",
   "metadata": {},
   "source": [
    "## Bag of Word (BOW)\n",
    "- frequency based encoding technique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb472068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f277ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf8f522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love nlp', 'i teach gen ai', 'i am working with iub']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27c89cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c77dc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ai', 'am', 'gen', 'iub', 'love', 'nlp', 'teach', 'with',\n",
       "       'working'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a7bc5",
   "metadata": {},
   "source": [
    "#### after stopwords modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ed0c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(vocabulary=unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "903d56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = vectorizer1.fit_transform(corpus)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12acb27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['working', 'i', 'am', 'nlp', 'gen', 'with', 'love', 'ai', 'iub',\n",
       "       'teach'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93917927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
