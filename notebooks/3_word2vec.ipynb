{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36e9ab4",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "- CBOW\n",
    "- Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2ede3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from gensim) (2.0.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: simpful==2.12.0 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso==1.8.1 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanjina\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tanjina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tanjina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"my name is Proma.\",\n",
    "    \"i used to teach introductory python!\",\n",
    "    \"Hi, I'm Tanjina Proma, a passionate Machine Learning Engineer.\",\n",
    "    \"I am enhancing my knowledge with the latest development in the field of Machine Learning and Data Science.\",\n",
    "    \"I have worked for more than four years, and I have a record of successfully implementing Computer Vision and Image Processing based pipelines with practical expertise using MLOps, deep learning & machine learning.\",\n",
    "    \"I am interested in enabling machine to understand sequence of information and act accordingly to make significant progress towards true artificial intelligence.\",\n",
    "    \"nlp is veyy amazing field!\",\n",
    "    \"i love working with nlp tasks, ml models, generative ai and agentic ai\",\n",
    "    \"we will try to build two models here.\",\n",
    "    \"word2vec and skip-gram .\",\n",
    "    \"we will also work on cleaning the text data lso known as data preprocessing.\",\n",
    "    \"my phone number is 23874875 2387465.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a9870bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my name is Proma 38745685 796 .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda2c3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is proma 38745685 796 .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b013965d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is Proma   .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\d+', '', text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b987a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60efa7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is Proma 38745685 796 '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.translate(str.maketrans('', '', string.punctuation))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4d75f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'name', 'is', 'Proma', '38745685', '796', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4986ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 =['my', 'name', 'is', 'Proma', '38745685', '796', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6601a20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'Proma', '38745685', '796', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in s1 if i not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc396d1",
   "metadata": {},
   "source": [
    "#### data preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a47eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    word = word_tokenize(text)\n",
    "    word = [i for i in word if i not in stopwords.words('english')]\n",
    "    return word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c19597c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my name is Proma.',\n",
       " 'i used to teach introductory python!',\n",
       " \"Hi, I'm Tanjina Proma, a passionate Machine Learning Engineer.\",\n",
       " 'I am enhancing my knowledge with the latest development in the field of Machine Learning and Data Science.',\n",
       " 'I have worked for more than four years, and I have a record of successfully implementing Computer Vision and Image Processing based pipelines with practical expertise using MLOps, deep learning & machine learning.',\n",
       " 'I am interested in enabling machine to understand sequence of information and act accordingly to make significant progress towards true artificial intelligence.',\n",
       " 'nlp is veyy amazing field!',\n",
       " 'i love working with nlp tasks, ml models, generative ai and agentic ai',\n",
       " 'we will try to build two models here.',\n",
       " 'word2vec and skip-gram .',\n",
       " 'we will also work on cleaning the text data lso known as data preprocessing.',\n",
       " 'my phone number is 23874875 2387465.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f84c1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = [word_preprocessing(sentence) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d01617cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['name', 'proma'],\n",
       " ['used', 'teach', 'introductory', 'python'],\n",
       " ['hi',\n",
       "  'im',\n",
       "  'tanjina',\n",
       "  'proma',\n",
       "  'passionate',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'engineer'],\n",
       " ['enhancing',\n",
       "  'knowledge',\n",
       "  'latest',\n",
       "  'development',\n",
       "  'field',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'data',\n",
       "  'science'],\n",
       " ['worked',\n",
       "  'four',\n",
       "  'years',\n",
       "  'record',\n",
       "  'successfully',\n",
       "  'implementing',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'image',\n",
       "  'processing',\n",
       "  'based',\n",
       "  'pipelines',\n",
       "  'practical',\n",
       "  'expertise',\n",
       "  'using',\n",
       "  'mlops',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'machine',\n",
       "  'learning'],\n",
       " ['interested',\n",
       "  'enabling',\n",
       "  'machine',\n",
       "  'understand',\n",
       "  'sequence',\n",
       "  'information',\n",
       "  'act',\n",
       "  'accordingly',\n",
       "  'make',\n",
       "  'significant',\n",
       "  'progress',\n",
       "  'towards',\n",
       "  'true',\n",
       "  'artificial',\n",
       "  'intelligence'],\n",
       " ['nlp', 'veyy', 'amazing', 'field'],\n",
       " ['love',\n",
       "  'working',\n",
       "  'nlp',\n",
       "  'tasks',\n",
       "  'ml',\n",
       "  'models',\n",
       "  'generative',\n",
       "  'ai',\n",
       "  'agentic',\n",
       "  'ai'],\n",
       " ['try', 'build', 'two', 'models'],\n",
       " ['wordvec', 'skipgram'],\n",
       " ['also',\n",
       "  'work',\n",
       "  'cleaning',\n",
       "  'text',\n",
       "  'data',\n",
       "  'lso',\n",
       "  'known',\n",
       "  'data',\n",
       "  'preprocessing'],\n",
       " ['phone', 'number']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52552cd8",
   "metadata": {},
   "source": [
    "## word2vec CBOW VS Skipram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18d1dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_cbow = Word2Vec(sentences = processed_corpus, vector_size = 100, window = 5, min_count = 1, sg = 0)\n",
    "word2vec_skipgram = Word2Vec(sentences = processed_corpus, vector_size = 100, window = 5, min_count = 1, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67fd90b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1d4fbbe9390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33951428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1d4fb910890>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39b21ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.7309992e-03,  2.1269498e-03, -8.6727820e-04, -9.2792604e-03,\n",
       "       -9.4224690e-03, -1.4448678e-03,  4.4651073e-03,  3.7713852e-03,\n",
       "       -6.5277466e-03, -6.9276802e-03, -5.0051529e-03, -2.3030832e-03,\n",
       "       -7.2661820e-03, -9.6169459e-03, -2.7032231e-03, -8.3713774e-03,\n",
       "       -6.0346872e-03, -5.6549856e-03, -2.3943253e-03, -1.7465742e-03,\n",
       "       -8.9535741e-03, -7.1239041e-04,  8.1392545e-03,  7.7078589e-03,\n",
       "       -7.2064442e-03, -3.7047921e-03,  3.0748833e-03, -9.5893797e-03,\n",
       "        1.4477592e-03,  6.5116934e-03,  5.7587791e-03, -8.7896213e-03,\n",
       "       -4.5100343e-03, -8.1746681e-03,  6.0565899e-06,  9.3054753e-03,\n",
       "        6.0187946e-03,  5.0790780e-03,  5.0743446e-03, -3.2619932e-03,\n",
       "        9.5663611e-03, -7.3796129e-03, -7.2492333e-03, -2.2619127e-03,\n",
       "       -7.7099638e-04, -3.2398917e-03, -6.2886550e-04,  7.4789836e-03,\n",
       "       -6.7566038e-04, -1.5957945e-03,  2.7472659e-03, -8.3960351e-03,\n",
       "        7.8324787e-03,  8.4979273e-03, -9.5690861e-03,  2.4388728e-03,\n",
       "        9.9008959e-03, -7.6659671e-03, -6.9905417e-03, -7.7087302e-03,\n",
       "        8.4162736e-03, -6.2414375e-04,  9.1901328e-03, -8.1844116e-03,\n",
       "        3.7274647e-03,  2.6617360e-03,  7.5008353e-04,  2.3590147e-03,\n",
       "       -7.5051785e-03, -9.3818931e-03,  2.3631575e-03,  6.1505800e-03,\n",
       "        7.9962090e-03,  5.7050874e-03, -7.1162469e-04,  8.2914997e-03,\n",
       "       -9.3749976e-03,  3.4473822e-03,  2.4384358e-04,  3.8057414e-03,\n",
       "        7.4042841e-03, -6.7128451e-03,  5.5606472e-03, -9.4525646e-03,\n",
       "       -8.2485972e-04, -8.6514037e-03, -5.0828122e-03,  9.3221506e-03,\n",
       "       -1.8460558e-03,  2.9138017e-03,  9.0891421e-03,  8.9310538e-03,\n",
       "       -8.1566460e-03, -2.9712452e-03,  9.9560842e-03,  5.0922926e-03,\n",
       "       -1.6042322e-03, -8.7070297e-03,  2.9551003e-03, -6.7138853e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_skipgram.wv[\"ai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f073c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_skipgram.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_skipgram.wv[\"ai\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efe5fad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intelligence', 0.3090762794017792),\n",
       " ('amazing', 0.2809133529663086),\n",
       " ('enabling', 0.19016465544700623)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_skipgram.wv.most_similar('ai', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c41f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.7264059e-03,  2.1139830e-03, -8.5774518e-04, -9.3173673e-03,\n",
       "       -9.4163120e-03, -1.4424702e-03,  4.4567222e-03,  3.7415526e-03,\n",
       "       -6.5285424e-03, -6.8916371e-03, -4.9903332e-03, -2.3063179e-03,\n",
       "       -7.2719823e-03, -9.6091107e-03, -2.7286063e-03, -8.3729671e-03,\n",
       "       -6.0275872e-03, -5.6880321e-03, -2.3781490e-03, -1.7439456e-03,\n",
       "       -8.9451028e-03, -7.0098025e-04,  8.1772916e-03,  7.6960740e-03,\n",
       "       -7.2047259e-03, -3.6578290e-03,  3.1110793e-03, -9.5707942e-03,\n",
       "        1.4641960e-03,  6.5301927e-03,  5.7301624e-03, -8.7744463e-03,\n",
       "       -4.5060366e-03, -8.1842784e-03,  2.2727456e-05,  9.2791039e-03,\n",
       "        6.0069719e-03,  5.0609880e-03,  5.0646798e-03, -3.2586774e-03,\n",
       "        9.5537324e-03, -7.3669986e-03, -7.2675594e-03, -2.2538498e-03,\n",
       "       -7.5736700e-04, -3.2136159e-03, -6.3393346e-04,  7.5103692e-03,\n",
       "       -6.8071764e-04, -1.6200556e-03,  2.7400213e-03, -8.3771218e-03,\n",
       "        7.8391079e-03,  8.5252170e-03, -9.5944619e-03,  2.4261591e-03,\n",
       "        9.9313902e-03, -7.6798680e-03, -6.9720098e-03, -7.7254963e-03,\n",
       "        8.4061483e-03, -6.7257887e-04,  9.1578504e-03, -8.1595741e-03,\n",
       "        3.7464963e-03,  2.6701055e-03,  7.3346781e-04,  2.3588536e-03,\n",
       "       -7.5117871e-03, -9.3600471e-03,  2.3418530e-03,  6.1776130e-03,\n",
       "        8.0029145e-03,  5.7208543e-03, -7.5361039e-04,  8.3005168e-03,\n",
       "       -9.3472591e-03,  3.4356897e-03,  2.4295996e-04,  3.8268813e-03,\n",
       "        7.3903594e-03, -6.7392569e-03,  5.5549238e-03, -9.4944807e-03,\n",
       "       -8.3228841e-04, -8.6653633e-03, -5.0758668e-03,  9.3075335e-03,\n",
       "       -1.8644184e-03,  2.9110196e-03,  9.1094477e-03,  8.9642303e-03,\n",
       "       -8.1947502e-03, -2.9878684e-03,  9.9461609e-03,  5.1210234e-03,\n",
       "       -1.6017620e-03, -8.7043932e-03,  2.9352922e-03, -6.6766581e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow.wv[\"ai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e92ad605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064583056"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow.wv.similarity('data', \"ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37c46b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " 'learning',\n",
       " 'data',\n",
       " 'field',\n",
       " 'models',\n",
       " 'ai',\n",
       " 'nlp',\n",
       " 'proma',\n",
       " 'processing',\n",
       " 'image',\n",
       " 'vision',\n",
       " 'computer',\n",
       " 'worked',\n",
       " 'based',\n",
       " 'implementing',\n",
       " 'successfully',\n",
       " 'pipelines',\n",
       " 'record',\n",
       " 'practical',\n",
       " 'years',\n",
       " 'four',\n",
       " 'expertise',\n",
       " 'number',\n",
       " 'development',\n",
       " 'science',\n",
       " 'mlops',\n",
       " 'latest',\n",
       " 'knowledge',\n",
       " 'enhancing',\n",
       " 'engineer',\n",
       " 'passionate',\n",
       " 'tanjina',\n",
       " 'im',\n",
       " 'hi',\n",
       " 'python',\n",
       " 'introductory',\n",
       " 'teach',\n",
       " 'used',\n",
       " 'using',\n",
       " 'interested',\n",
       " 'deep',\n",
       " 'phone',\n",
       " 'ml',\n",
       " 'generative',\n",
       " 'agentic',\n",
       " 'try',\n",
       " 'build',\n",
       " 'two',\n",
       " 'wordvec',\n",
       " 'skipgram',\n",
       " 'also',\n",
       " 'work',\n",
       " 'cleaning',\n",
       " 'text',\n",
       " 'lso',\n",
       " 'known',\n",
       " 'preprocessing',\n",
       " 'tasks',\n",
       " 'working',\n",
       " 'love',\n",
       " 'make',\n",
       " 'enabling',\n",
       " 'understand',\n",
       " 'sequence',\n",
       " 'information',\n",
       " 'act',\n",
       " 'accordingly',\n",
       " 'significant',\n",
       " 'amazing',\n",
       " 'progress',\n",
       " 'towards',\n",
       " 'true',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'veyy',\n",
       " 'name']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12c5a961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('years', 0.319225937128067),\n",
       " ('progress', 0.23917101323604584),\n",
       " ('used', 0.20405329763889313),\n",
       " ('love', 0.198649063706398),\n",
       " ('information', 0.19480089843273163)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow.wv.most_similar('proma', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e94eaf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('years', 0.3198002576828003),\n",
       " ('progress', 0.23962153494358063),\n",
       " ('used', 0.20427468419075012),\n",
       " ('love', 0.19915235042572021),\n",
       " ('information', 0.1955452561378479)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_skipgram.wv.most_similar('proma', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['AI-assisted legal research helps lawyers analyze case laws more efficiently.',\n",
    " 'AI is used in astronomy to analyze vast amounts of cosmic data.',\n",
    " 'Smart homes use AI for automation and energy efficiency.',\n",
    " 'AI is revolutionizing the way people search for information online.',\n",
    " 'AI-based handwriting recognition improves digitization and document processing.',\n",
    " 'The use of AI in wildlife conservation helps monitor endangered species.',\n",
    " 'AI is shaping the future of content creation in journalism and storytelling.',\n",
    " 'AI-driven job matching platforms help connect candidates with suitable employers.',\n",
    " 'The financial sector uses AI to assess credit risk and detect fraudulent transactions.',\n",
    " 'AI in manufacturing enhances efficiency and reduces production errors.',\n",
    " 'Wearable technology powered by AI helps monitor personal health metrics.',\n",
    " 'The role of AI in sports analytics improves team performance analysis.',\n",
    " 'AI is helping researchers discover new materials and chemical compounds.',\n",
    " 'AI in law enforcement aids in criminal investigations and predictive policing.',\n",
    " 'AI-driven autonomous ships are transforming maritime transportation.',\n",
    " 'AI-powered smart grids enhance energy distribution and consumption efficiency.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3b47f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ed7adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = word2vec_cbow.wv\n",
    "vocab = list(word_vectors.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63d66a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01cb4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([word_vectors[i] for i in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c469788a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_new_embeddings \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(x)\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1119\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1119\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:963\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    957\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[t-SNE] Indexed \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples in \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124ms...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    958\u001b[0m             n_samples, duration\n\u001b[0;32m    959\u001b[0m         )\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    962\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 963\u001b[0m distances_nn \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mkneighbors_graph(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    964\u001b[0m duration \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:988\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors_graph\u001b[1;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[0;32m    985\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_queries \u001b[38;5;241m*\u001b[39m n_neighbors)\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 988\u001b[0m     A_data, A_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X, n_neighbors, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    989\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(A_data)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:824\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    817\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    820\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[0;32m    821\u001b[0m     )\n\u001b[0;32m    822\u001b[0m )\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[1;32m--> 824\u001b[0m     results \u001b[38;5;241m=\u001b[39m ArgKmin\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    825\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    826\u001b[0m         Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[0;32m    827\u001b[0m         k\u001b[38;5;241m=\u001b[39mn_neighbors,\n\u001b[0;32m    828\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_,\n\u001b[0;32m    829\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_,\n\u001b[0;32m    830\u001b[0m         strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    831\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[0;32m    836\u001b[0m ):\n\u001b[0;32m    837\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[0;32m    838\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[0;32m    839\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:289\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin64\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    278\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    279\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    286\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    290\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    291\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m    292\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    293\u001b[0m         metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m    294\u001b[0m         chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[0;32m    295\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39mmetric_kwargs,\n\u001b[0;32m    296\u001b[0m         strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[0;32m    297\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly float64 or float32 datasets pairs are supported at this time, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot: X.dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Y.dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m )\n",
      "File \u001b[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx:584\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py:139\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m threadpoolctl\u001b[38;5;241m.\u001b[39mthreadpool_limits(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(limits, user_api)\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_threadpool_limits()\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m modules \u001b[38;5;241m=\u001b[39m _ThreadpoolInfo(prefixes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes,\n\u001b[0;32m    269\u001b[0m                           user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits:\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_modules()\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:373\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dyld()\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_enum_process_module_ex()\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:485\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_module_from_path(filepath)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     kernel_32\u001b[38;5;241m.\u001b[39mCloseHandle(h_process)\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[0;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[1;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class(filepath, prefix, user_api, internal_api)\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_version()\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[1;32mc:\\Users\\Tanjina\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[1;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "x_new_embeddings = tsne.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x_new_embeddings[: , 0] , x_new_embeddings[:,1] , marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13808f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai',\n",
       " 'helps',\n",
       " 'efficiency',\n",
       " 'smart',\n",
       " 'improves',\n",
       " 'analyze',\n",
       " 'aidriven',\n",
       " 'energy',\n",
       " 'use',\n",
       " 'monitor',\n",
       " 'consumption',\n",
       " 'digitization',\n",
       " 'document',\n",
       " 'processing',\n",
       " 'wildlife',\n",
       " 'conservation',\n",
       " 'shaping',\n",
       " 'endangered',\n",
       " 'species',\n",
       " 'handwriting',\n",
       " 'future',\n",
       " 'content',\n",
       " 'creation',\n",
       " 'journalism',\n",
       " 'storytelling',\n",
       " 'job',\n",
       " 'matching',\n",
       " 'platforms',\n",
       " 'recognition',\n",
       " 'search',\n",
       " 'aibased',\n",
       " 'online',\n",
       " 'legal',\n",
       " 'research',\n",
       " 'lawyers',\n",
       " 'case',\n",
       " 'laws',\n",
       " 'efficiently',\n",
       " 'used',\n",
       " 'astronomy',\n",
       " 'vast',\n",
       " 'amounts',\n",
       " 'cosmic',\n",
       " 'data',\n",
       " 'homes',\n",
       " 'automation',\n",
       " 'revolutionizing',\n",
       " 'way',\n",
       " 'people',\n",
       " 'connect',\n",
       " 'information',\n",
       " 'help',\n",
       " 'candidates',\n",
       " 'distribution',\n",
       " 'suitable',\n",
       " 'analysis',\n",
       " 'helping',\n",
       " 'researchers',\n",
       " 'discover',\n",
       " 'new',\n",
       " 'materials',\n",
       " 'chemical',\n",
       " 'compounds',\n",
       " 'law',\n",
       " 'enforcement',\n",
       " 'aids',\n",
       " 'criminal',\n",
       " 'investigations',\n",
       " 'predictive',\n",
       " 'policing',\n",
       " 'autonomous',\n",
       " 'ships',\n",
       " 'transforming',\n",
       " 'maritime',\n",
       " 'transportation',\n",
       " 'aipowered',\n",
       " 'grids',\n",
       " 'enhance',\n",
       " 'performance',\n",
       " 'team',\n",
       " 'analytics',\n",
       " 'manufacturing',\n",
       " 'employers',\n",
       " 'financial',\n",
       " 'sector',\n",
       " 'uses',\n",
       " 'assess',\n",
       " 'credit',\n",
       " 'risk',\n",
       " 'detect',\n",
       " 'fraudulent',\n",
       " 'transactions',\n",
       " 'enhances',\n",
       " 'sports',\n",
       " 'reduces',\n",
       " 'production',\n",
       " 'errors',\n",
       " 'wearable',\n",
       " 'technology',\n",
       " 'powered',\n",
       " 'personal',\n",
       " 'health',\n",
       " 'metrics',\n",
       " 'role',\n",
       " 'aiassisted']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x_new_embedings[: , 0] , x_new_embedings[:,1] , marker='o')\n",
    "\n",
    "for i ,words in enumerate(vocab[:len(x_new_embedings)]):\n",
    "    plt.annotate(words,xy=(x_new_embedings[i,0],x_new_embedings[i,1]))\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Barack Obama was the 44th President of the United States.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2360dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea121e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk,pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62304704",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_chunk(pos_tag(word_tokenize(text)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
